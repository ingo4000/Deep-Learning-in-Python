{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n# Welcome to Natural Language Processing!\n\nThis course is about Natural Language Processing (NLP) with Keras/TensorFlow and the HuggingFace collection of language models. NLP is the field in statistical learning that teaches computers how to 'understand' language. (Or at least, how to make it appear it does &#128521;.)\n\nIn this course you will learn to work with the most current NLP techniques that build on (deep) neural networks. You will\n\n- Use state of the art Transformer models to train a document classifier with Keras\n- Train your own word vector embeddings \n- Learn the fundamentals behind autoregressive language models using RNNs \n- Use pretrained models to complete sentences \n- Let state of the art models from Huggingface answer questions \n\n\nIf you've taken the Introduction to Deep Learning course, you'll know everything you need to be successful.\n\nNow let's get started!\n\n# Introduction","metadata":{}},{"cell_type":"markdown","source":"The `transformers` library gives access to a host of pretrained language models for various NLP tasks:\n\n- `feature-extraction` (get the vector representation of a text)\n- `fill-mask`\n- `ner` (named entity recognition)\n- `question-answering`\n- `sentiment-analysis`\n- `summarization`\n- `text-generation`\n- `translation`\n- `zero-shot-classification`\n\nThe easiest way to access these models is by means of the `pipeline` object. The `pipeline` object allows you to _instantiate_ a model as an object that you can call on a string of text. The object takes care of preprocessing the text (tokenization, etc.), running the model, and turning the output into and easy understandable and use format.\n\nLet's take a look at some of these models.\n\n# Sentiment analysis\n\nThe first item on the list that we'll try is `sentiment-analysis`","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:41:12.472821Z","iopub.execute_input":"2023-11-23T08:41:12.473579Z","iopub.status.idle":"2023-11-23T08:41:41.357858Z","shell.execute_reply.started":"2023-11-23T08:41:12.473480Z","shell.execute_reply":"2023-11-23T08:41:41.356179Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a74194cd3525494aa30cccc864484c05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a33a9b7f38a4b3bb499e967a28756c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a8673f050d945ac9ecd59af7246e7f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e22a2d50a73466cad0639d58d1b929a"}},"metadata":{}}]},{"cell_type":"markdown","source":"As you can see, the first thing that the call to `pipeline` does is (besides complaining that we weren't specific about the model we wantedâ€”more on that later) to download files. These are the pretrained model files that are stored on the [ðŸ¤— HuggingFace repository](https://huggingface.co). If they are not available (yet) in your current working environment, they need to be downloaded. The `transformer` library takes care of this for you _automagically_.\n\nLet's see what `classifier` does:","metadata":{}},{"cell_type":"code","source":"classifier(\n    [\"It is a new day, the sun is shining, I feel good.\", \n     \"I love this NLP stuff!\",\n     \"This muscle ache is killing me\",\n     \"I can reassure you that your headaches are now a sorrow of the past.\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:41:52.855978Z","iopub.execute_input":"2023-11-23T08:41:52.856733Z","iopub.status.idle":"2023-11-23T08:41:53.185670Z","shell.execute_reply.started":"2023-11-23T08:41:52.856691Z","shell.execute_reply":"2023-11-23T08:41:53.184014Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[{'label': 'POSITIVE', 'score': 0.9998846054077148},\n {'label': 'POSITIVE', 'score': 0.9998706579208374},\n {'label': 'NEGATIVE', 'score': 0.9995550513267517},\n {'label': 'NEGATIVE', 'score': 0.9915013313293457}]"},"metadata":{}}]},{"cell_type":"markdown","source":"It's clear that this model is not very good at recognizing double negatives... (But then again, are humans good at that?)","metadata":{}},{"cell_type":"markdown","source":"# Question answering\n\nNext we'll try `question-answering`. In question answering, the model takes two strings:\n\n1. A contextâ€”a text in which the answer can be found, and\n2. A question that is _assumed to be_ answerable with the text in the context string.\n\nThe model was trained to predict the start and end of the segment (in terms of the location of the first and last character in the _context_ that holds the answer to the _question_.\n\nSo for instance, if\n\n`context` = _\"Lucy had named the kitten Purr.\"_\n\nand the question is _\"What was the name of the cat?\"_, the model will try to predict `(26,30)`, because those are the start and end of the substring that contains \"Purr\".","metadata":{}},{"cell_type":"code","source":"question_answerer = pipeline(\"question-answering\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:42:02.839467Z","iopub.execute_input":"2023-11-23T08:42:02.840045Z","iopub.status.idle":"2023-11-23T08:42:25.438452Z","shell.execute_reply.started":"2023-11-23T08:42:02.839994Z","shell.execute_reply":"2023-11-23T08:42:25.437151Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac28e44af97d4d87be7c5162aea2bec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d0e7860cca64acd849c3dc04ae46623"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e1475a45e6e45f7a715def84267c1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab9dcf3d21eb4421861b78ef2c078f5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96e2ee6ec4044bfa81f73692fb7162d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Notice that a different model is downloaded. For most tasks, a dedicated model needs to be downloaded. Some of the models are really large (more than 1GB) and so we won't try all of them here. (But feel free to play around and have some fun with them! Basic usage documentation can be found on [ðŸ¤— HuggingFace](https://huggingface.co).)","metadata":{}},{"cell_type":"code","source":"print(question_answerer(\n    context=\"His daughter Lucy had named the kitten Purr\",\n    question=\"What was the name of the cat?\",\n))\nprint(question_answerer(\n    context=\"His daughter Lucy had named the kitten Purr\",\n    question=\"Who owns the cat?\",\n))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:42:40.213589Z","iopub.execute_input":"2023-11-23T08:42:40.214714Z","iopub.status.idle":"2023-11-23T08:42:40.304441Z","shell.execute_reply.started":"2023-11-23T08:42:40.214664Z","shell.execute_reply":"2023-11-23T08:42:40.303316Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'score': 0.5847036838531494, 'start': 32, 'end': 43, 'answer': 'kitten Purr'}\n{'score': 0.46665525436401367, 'start': 13, 'end': 17, 'answer': 'Lucy'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The model does seem to 'know' to distinguish between the two names in the sentence. Let's try something more complicated:","metadata":{}},{"cell_type":"code","source":"TEXT = \"\"\"Key developments in artificial neural networks and deep learning came not from \n    computer science, but from cognitive and mathematical psychology. Computer scientists \n    accelerated the development with more powerful computers and implementation frameworks.\"\"\"\n\n[  question_answerer(question=\"In which academic field was deep learning developed?\", context = TEXT), \n   question_answerer(question=\"What was the role of computer science?\",context=TEXT)]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:43:23.938381Z","iopub.execute_input":"2023-11-23T08:43:23.938880Z","iopub.status.idle":"2023-11-23T08:43:24.077944Z","shell.execute_reply.started":"2023-11-23T08:43:23.938841Z","shell.execute_reply":"2023-11-23T08:43:24.076207Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'score': 0.4984089136123657,\n  'start': 111,\n  'end': 148,\n  'answer': 'cognitive and mathematical psychology'},\n {'score': 0.8162105083465576,\n  'start': 175,\n  'end': 186,\n  'answer': 'accelerated'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Text generation with GPT2\n\nRemember the complaint about not being specific about the model? We can fix that by specifying a specific model (in stead of relying on default choices). Here we'll use the ðŸ¤— HuggingFace simplified version of the famous GPT2 model (the precursor to GPT3) to generate some text.","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\ngenerator = pipeline(\"text-generation\", model=\"distilgpt2\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:43:42.827495Z","iopub.execute_input":"2023-11-23T08:43:42.827962Z","iopub.status.idle":"2023-11-23T08:44:12.941884Z","shell.execute_reply.started":"2023-11-23T08:43:42.827925Z","shell.execute_reply":"2023-11-23T08:44:12.940230Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b22b0920e124993ab7a555b56004477"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c09abc72723e43e3b20e0e970253b2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57bf721d30c140edb1e84e30cffd1090"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a67dc8a140a043cdb8c5dbea3dd67822"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9a82c9fcc6f4cec825fcee6504037d3"}},"metadata":{}}]},{"cell_type":"code","source":"generator(\"Welcome to the natural language processing (NLP) module of Deep Learning in Python. In this course, you will learn \",\n    max_length=100, num_return_sequences=2, pad_token_id=50256)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:46:00.807531Z","iopub.execute_input":"2023-11-23T08:46:00.808504Z","iopub.status.idle":"2023-11-23T08:46:05.454239Z","shell.execute_reply.started":"2023-11-23T08:46:00.808451Z","shell.execute_reply":"2023-11-23T08:46:05.452834Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Welcome to the natural language processing (NLP) module of Deep Learning in Python. In this course, you will learn ã… ã… ã… , as well as learn how to construct a set of Python words using Python 2.'},\n {'generated_text': 'Welcome to the natural language processing (NLP) module of Deep Learning in Python. In this course, you will learn ä»–ä»•å¥½åˆä½•å¥½åœ° (èŽ£çŠ¶è“¤äº›ç¤¾, æª»è“¤äº›ç¤¾, ç¡¾ åª»è“¤äº›ç¤¾, ç¡¾ åª»è“¤äº›ç¤¾, ç¡¾'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"Not exactly sensible, nor Shakespeare, and not exactly GPT3 either, but you get the drift.\n\n\n# State of the art NLP models\n\nAll of these models (plus the models for the NLP tasks listed earlier) were built using what is known as a _Transformer_ architecture. We'll come back to what that entails in more detail in a later tutorial. For now, let's recognize that these types of language models are currently (in 2022) the absolute state of the art. \n\nThe models we've seen here are not the best available models, but they do share the same basic architecture with the models that are the bestâ€”what's sets the latter apart is not only their performance on a litany of tasks, but certainly also their size: The models here were limited to under 500Mb in file size to store the weights, but the best models are several Gb and larger. \n\nAll of these models have been trained on enormous text corpora, such as the [Common Crawl](https://commoncrawl.org/), [Wikipedia (EN)](https://huggingface.co/datasets/wikipedia), or [WebText (EN)](https://paperswithcode.com/dataset/webtext), to repressent the statistical dependancies between words, in an unsupervised way. \n\n## How?\n\nYou may wonder how, and the answer is relatively simple: by predicting words from context words. This can take various forms, but let's focus on two:\n\n1. Fill in the blank: Predict the (likelihood of) word that goes in the empty space in for example `\"the cat ___ the mouse\"` (e.g., `ate`, `killed`, `caught` are all likely, but `painted`, `sung`, `addopted` are all unlikely).\n2. Predict the next token, given the sequence of tokens so far, for each token in a piece of text. (We say token here instead of word, because a token may also be a punctuation character, or the _End Of Sequence_ token `<EOS>`. For example, in `\"the cat chased the mouse\"` the model tries to predict \n  \n  $P({\\tt the})$,\n\n  $P({\\tt cat}|{\\tt the})$,\n\n  $P({\\tt chased}|{\\tt the, cat})$,\n\n  $P({\\tt the}|{\\tt the, cat, chased})$,\n\n  $P({\\tt mouse}|{\\tt the, cat, chased, the})$, and\n\n  $P({\\tt <\\!EOS\\!>}|{\\tt the, cat, chased, the, mouse})$\n\nThe difference between the two methods isn't very large, but notice that the latter method can learn the probability for the entire sentence: From the rules of conditional probability \n\n$$P(A,B) = P(A)P(B|A),$$ and more generally, $$P(A,B,C,\\ldots) = P(A)P(B,C,\\ldots|A).$$\n\nApplying this recursively, we can compute \n\n$$P(A,B,C,\\ldots) = P(A)\\cdot P(B|A)\\cdot   P(C|A,B)\\cdot P(\\ldots|A,B,C) \\cdot \\cdots$$\n\nHence, if we took a random sentence from the text of say the internet, we can write the probability that the sentence is equal to `\"the cat chased the mouse\"` as\n\n$$P({\\tt the, cat, chased, the, mouse, <\\!EOS\\!>}) =  \nP({\\tt the})\\, \nP({\\tt cat}|{\\tt the})\\,\nP({\\tt chased}|{\\tt the, cat})\\, P({\\tt the}|{\\tt the, cat, chased})\\,\nP({\\tt mouse}|{\\tt the, cat, chased, the})\\, \nP({\\tt <\\!EOS\\!>}|{\\tt the, cat, chased, the, mouse}).$$\n\nNotice that we can do this with any sentence. Specifically, any sentence of any length in principle (in practice computational problems mount as sentences become larger). \n\nContrast this to the first method of training (the fill-in-the-blank method): This method only learns the conditional probabilities of the form \n\n$$P(X_0 | X_{p}, \\ldots, X_{-1}, X_1, \\ldots, X_q).$$\n\nHere $p$ and $q$ are integers that specify a window around the focus token $X_0$. Usually, $p \\lt 0 \\le q$, but this doesn't have to be the case. For our running example this would be, for instance,\n\n$$P(X_0 = {\\tt chased} | X_{-2}={\\tt the}, X_{-1}={\\tt cat}, X_1={\\tt the}, X_2={\\tt mouse}),$$ \n\n$$P(X_0 = {\\tt caught} | X_{-2}={\\tt the}, X_{-1}={\\tt cat}, X_1={\\tt the}, X_2={\\tt mouse}),$$ \n\n$$P(X_0 = {\\tt killed} | X_{-2}={\\tt the}, X_{-1}={\\tt cat}, X_1={\\tt the}, X_2={\\tt mouse}),$$ \n\netc.\n","metadata":{}},{"cell_type":"markdown","source":"# Your Turn\n\nNow that you've seen a few uses of the ðŸ¤— HuggingFace `transformer` library for NLP, it's your turn to try it to teach a neural network to [recognize sentences with the same meaning](https://www.kaggle.com/code/datasniffer/nlp-ex1/).\n\n\n---\n\n<small>\n    \n_For Deep Learning in Python (2022)._\n    \n</small>\n","metadata":{}}]}